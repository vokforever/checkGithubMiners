import asyncio
import json
import os
import logging
import sys
import locale
import ctypes
import traceback
import shutil
import re
import gc
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, Optional, List, Set, Tuple
from aiohttp import ClientSession, ClientError, ClientResponseError, TCPConnector, ClientTimeout
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import CommandStart, Command
from aiogram.types import Message, CallbackQuery
from aiogram.utils.keyboard import InlineKeyboardBuilder
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä–∞
try:
    from modern_telegram_formatter import formatter, convert_markdown_to_telegram
    MODERN_FORMATTER_AVAILABLE = True
except ImportError:
    MODERN_FORMATTER_AVAILABLE = False
    logging.warning("–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –±–∞–∑–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏")

# --- –ù–ê–°–¢–†–û–ô–ö–ê –ö–û–î–ò–†–û–í–ö–ò –î–õ–Ø WINDOWS ---
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8', errors='backslashreplace')
    sys.stderr.reconfigure(encoding='utf-8', errors='backslashreplace')
    try:
        kernel32 = ctypes.windll.kernel32
        kernel32.SetConsoleOutputCP(65001)
    except Exception as e:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É UTF-8: {e}")

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø VPS ---
BOT_TOKEN = os.getenv("BOT_TOKEN")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN", None)
CHANNEL_ID = os.getenv("CHANNEL_ID")
ADMIN_ID = int(os.getenv("ADMIN_ID", "0"))
DONATE_URL = "https://boosty.to/vokforever/donate"

# VPS-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
VPS_PROFILE = os.getenv("VPS_PROFILE", "low_power")
MAX_CONCURRENT_REQUESTS = int(os.getenv("MAX_CONCURRENT_REQUESTS", "2"))
REQUEST_TIMEOUT = int(os.getenv("REQUEST_TIMEOUT", "25"))
BATCH_SIZE = int(os.getenv("BATCH_SIZE", "3"))
MEMORY_THRESHOLD_MB = int(os.getenv("MEMORY_THRESHOLD_MB", "75"))
CACHE_TTL_HOURS = int(os.getenv("CACHE_TTL_HOURS", "4"))

# –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –ø—Ä–æ–≤–µ—Ä–∫–∏
MIN_CHECK_INTERVAL_MINUTES = int(os.getenv("MIN_CHECK_INTERVAL", "30"))
MAX_CHECK_INTERVAL_MINUTES = int(os.getenv("MAX_CHECK_INTERVAL", "2880"))
DEFAULT_CHECK_INTERVAL_MINUTES = int(os.getenv("DEFAULT_CHECK_INTERVAL", "720"))

# –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
MAX_RETRIES = 2  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 3 –¥–æ 2
RETRY_DELAY = 1  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 2 –¥–æ 1
HISTORY_DAYS = 14  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 30 –¥–æ 14 –¥–Ω–µ–π
PRIORITY_UPDATE_DAYS = 7

# --- –°–ü–ò–°–û–ö –†–ï–ü–û–ó–ò–¢–û–†–ò–ï–í ---
REPOS = [
    "andru-kun/wildrig-multi",
    "OneZeroMiner/onezerominer", 
    "trexminer/T-Rex",
    "xmrig/xmrig",
    "Lolliedieb/lolMiner-releases",
    "doktor83/SRBMiner-Multi",
    "nicehash/nicehashminer",
    "pooler/cpuminer",
    "rplant8/cpuminer-opt-rplant",
    "JayDDee/cpuminer-opt",
    "alephium/gpu-miner"
]

# --- –ü–ê–†–ê–ú–ï–¢–†–´ –ü–†–ò–û–†–ò–¢–ï–¢–ù–û–ô –ü–†–û–í–ï–†–ö–ò ---
PRIORITY_THRESHOLD_HIGH = 0.5
PRIORITY_THRESHOLD_LOW = 0.1

# --- –§–ê–ô–õ–´ –•–†–ê–ù–ï–ù–ò–Ø –î–ê–ù–ù–´–• ---
STATE_FILE = "last_releases.json"
FILTERS_FILE = "user_filters.json"
HISTORY_FILE = "releases_history.json"
USERS_FILE = "users.json"
STATISTICS_FILE = "bot_statistics.json"

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
BACKUP_DIR = "backups"
if not os.path.exists(BACKUP_DIR):
    os.makedirs(BACKUP_DIR)

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ---
def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è VPS"""
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è VPS
    if VPS_PROFILE == "ultra_low_power":
        log_level = logging.WARNING
        enable_file_logging = False
    elif VPS_PROFILE == "low_power":
        log_level = logging.INFO
        enable_file_logging = True
    else:
        log_level = logging.INFO
        enable_file_logging = True
    
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
    )
    
    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ (–≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–µ–Ω)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    console_handler.setLevel(log_level)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ—Ä–Ω–µ–≤–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)
    root_logger.addHandler(console_handler)
    
    # –§–∞–π–ª–æ–≤–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–µ–π —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏
    if enable_file_logging:
        # –û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥-—Ñ–∞–π–ª —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞
        file_handler = logging.FileHandler(
            f'{log_dir}/bot_{datetime.now().strftime("%Y%m%d")}.log', 
            encoding='utf-8'
        )
        file_handler.setFormatter(formatter)
        file_handler.setLevel(logging.INFO)
        root_logger.addHandler(file_handler)
        
        # –õ–æ–≥ –æ—à–∏–±–æ–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
        error_handler = logging.FileHandler(
            f'{log_dir}/errors_{datetime.now().strftime("%Y%m%d")}.log',
            encoding='utf-8'
        )
        error_handler.setFormatter(formatter)
        error_handler.setLevel(logging.ERROR)
        root_logger.addHandler(error_handler)
    
    return logging.getLogger(__name__)

logger = setup_logging()

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –û–ß–ò–°–¢–ö–ò ---
def clean_markdown_text(text: str) -> str:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ Markdown –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤"""
    if not text:
        return text
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã –≤–º–µ—Å—Ç–æ —Å–ª–æ–∂–Ω—ã—Ö regex
    text = text.replace('**', '').replace('__', '').replace('```', '').replace('~~', '')
    text = re.sub(r'[\*_~`|]', '', text)
    return text.strip()

def clean_text_for_telegram(text: str) -> str:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è Telegram"""
    if not text:
        return text
    
    # –ë–∞–∑–æ–≤—ã–µ –∑–∞–º–µ–Ω—ã
    text = re.sub(r'<[^>]+>', '', text)
    text = clean_markdown_text(text)
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\{.*?\}', '', text)
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    text = re.sub(r' +', ' ', text)
    
    return text.strip()

def escape_markdown(text: str) -> str:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ Markdown"""
    if not text:
        return ""
    
    escape_chars = '_*[]()~`>#+='
    escaped_text = ""
    for char in text:
        if char in escape_chars:
            escaped_text += f'\\{char}'
        else:
            escaped_text += char
    
    return escaped_text

def validate_telegram_text(text: str, max_length: int = 4096) -> str:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è Telegram —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª–∏–Ω—ã"""
    if not text:
        return ""
    
    if len(text) > max_length:
        words = text[:max_length-3].rsplit(' ', 1)
        if len(words) > 1:
            text = words[0] + "..."
        else:
            text = text[:max_length-3] + "..."
    
    text = clean_text_for_telegram(text)
    return text

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ö–õ–ê–°–° –î–õ–Ø –£–ü–†–ê–í–õ–ï–ù–ò–Ø –ü–†–ò–û–†–ò–¢–ï–¢–ê–ú–ò ---
class RepositoryPriorityManager:
    def __init__(self):
        self.priorities = {}
        self.last_priority_update = None
        self.supabase_manager = None
        self.db_synced = False
        
        try:
            from supabase_config import SupabaseManager
            self.supabase_manager = SupabaseManager()
            logger.info("SupabaseManager —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except ImportError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å SupabaseManager: {e}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ SupabaseManager: {e}")

    def _load_priorities_from_db(self) -> Dict[str, Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Supabase"""
        if not self.supabase_manager:
            logger.error("SupabaseManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã")
            raise RuntimeError("SupabaseManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        try:
            result = self.supabase_manager.get_repository_priorities()
            
            if result:
                db_priorities = {}
                for record in result:
                    repo_name = record.get('repo_name')
                    if repo_name in REPOS:
                        db_priorities[repo_name] = {
                            'update_count': record.get('update_count', 0),
                            'last_update': record.get('last_update'),
                            'check_interval': record.get('check_interval', DEFAULT_CHECK_INTERVAL_MINUTES),
                            'priority_score': float(record.get('priority_score', 0.0)),
                            'last_check': record.get('last_check'),
                            'consecutive_failures': record.get('consecutive_failures', 0),
                            'total_checks': record.get('total_checks', 0),
                            'average_response_time': float(record.get('average_response_time', 0.0))
                        }

                # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                for repo in REPOS:
                    if repo not in db_priorities:
                        db_priorities[repo] = self._create_default_priority()

                self.db_synced = True
                logger.info(f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –ë–î: {len(db_priorities)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
                return db_priorities
            else:
                logger.warning("–í –ë–î –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞—Ö, —Å–æ–∑–¥–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ")
                return {repo: self._create_default_priority() for repo in REPOS}

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ –∏–∑ –ë–î: {e}")
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∏–∑ –ë–î: {e}")

    def initialize_priorities(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
        self.priorities = self._load_priorities_from_db()
        self.last_priority_update = datetime.now(timezone.utc)

    def _create_default_priority(self) -> Dict:
        return {
            'update_count': 0,
            'last_update': None,
            'check_interval': DEFAULT_CHECK_INTERVAL_MINUTES,
            'priority_score': 0.0,
            'last_check': None,
            'consecutive_failures': 0,
            'total_checks': 0,
            'average_response_time': 0.0
        }

    def _save_priorities_to_db(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Supabase"""
        if not self.supabase_manager:
            logger.error("SupabaseManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã")
            raise RuntimeError("SupabaseManager –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        try:
            priorities_data = {}
            for repo_name, repo_data in self.priorities.items():
                priorities_data[repo_name] = {
                    'update_count': repo_data.get('update_count', 0),
                    'last_update': repo_data.get('last_update'),
                    'check_interval': repo_data.get('check_interval', DEFAULT_CHECK_INTERVAL_MINUTES),
                    'priority_score': repo_data.get('priority_score', 0.0),
                    'last_check': repo_data.get('last_check'),
                    'consecutive_failures': repo_data.get('consecutive_failures', 0),
                    'total_checks': repo_data.get('total_checks', 0),
                    'average_response_time': repo_data.get('average_response_time', 0.0)
                }
            
            self.supabase_manager.store_repository_priorities({'priorities': priorities_data})
            logger.info(f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î: {len(priorities_data)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ –≤ –ë–î: {e}")
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –≤ –ë–î: {e}")

    def _save_priorities(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ë–î"""
        self._save_priorities_to_db()

    def get_priority(self, repo: str) -> Dict:
        if repo not in self.priorities:
            self.priorities[repo] = self._create_default_priority()
            self._save_priorities_to_db()
        return self.priorities[repo]

    def record_update(self, repo: str):
        priority_data = self.get_priority(repo)
        priority_data['update_count'] += 1
        priority_data['last_update'] = datetime.now(timezone.utc).isoformat()
        priority_data['consecutive_failures'] = 0
        self._save_priorities_to_db()
        logger.info(f"–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è {repo}. –í—Å–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π: {priority_data['update_count']}")

    def record_check(self, repo: str, success: bool = True, response_time: float = 0.0):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        priority_data = self.get_priority(repo)
        priority_data['total_checks'] += 1
        priority_data['last_check'] = datetime.now(timezone.utc).isoformat()
        
        if success:
            priority_data['consecutive_failures'] = 0
            if priority_data['average_response_time'] > 0:
                priority_data['average_response_time'] = (
                    priority_data['average_response_time'] + response_time
                ) / 2
            else:
                priority_data['average_response_time'] = response_time
        else:
            priority_data['consecutive_failures'] += 1
            
        self._save_priorities_to_db()

    def should_update_priorities(self) -> bool:
        if not self.last_priority_update:
            return True
        return datetime.now(timezone.utc) - self.last_priority_update > timedelta(hours=6)

    def update_priorities(self, history_manager):
        logger.info("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")

        cutoff_date = datetime.now(timezone.utc) - timedelta(days=PRIORITY_UPDATE_DAYS)
        updated_count = 0

        for repo in REPOS:
            update_count = 0
            for rel in history_manager.history:
                if rel['repo_name'] == repo:
                    try:
                        pub_date = datetime.fromisoformat(rel['published_at'].replace('Z', '+00:00'))
                        if pub_date >= cutoff_date:
                            update_count += 1
                    except:
                        continue

            priority_score = update_count / PRIORITY_UPDATE_DAYS
            existing_data = self.priorities.get(repo, self._create_default_priority())

            # –£—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–µ—É–¥–∞—á
            failure_penalty = min(existing_data.get('consecutive_failures', 0) * 0.1, 0.5)
            adjusted_score = max(0, priority_score - failure_penalty)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å —É—á–µ—Ç–æ–º –ø—Ä–æ—Ñ–∏–ª—è VPS
            if adjusted_score >= PRIORITY_THRESHOLD_HIGH:
                check_interval = MIN_CHECK_INTERVAL_MINUTES
            elif adjusted_score <= PRIORITY_THRESHOLD_LOW:
                check_interval = MAX_CHECK_INTERVAL_MINUTES
            else:
                ratio = (adjusted_score - PRIORITY_THRESHOLD_LOW) / (PRIORITY_THRESHOLD_HIGH - PRIORITY_THRESHOLD_LOW)
                check_interval = int(
                    MAX_CHECK_INTERVAL_MINUTES - ratio * (MAX_CHECK_INTERVAL_MINUTES - MIN_CHECK_INTERVAL_MINUTES)
                )

            new_priority_data = {
                **existing_data,
                'update_count': update_count,
                'check_interval': check_interval,
                'priority_score': round(adjusted_score, 3)
            }

            if (repo not in self.priorities or
                    abs(self.priorities[repo]['check_interval'] - check_interval) > 5 or
                    abs(self.priorities[repo]['priority_score'] - adjusted_score) > 0.01):
                updated_count += 1

            self.priorities[repo] = new_priority_data

        self.last_priority_update = datetime.now(timezone.utc)
        self._save_priorities_to_db()

        logger.info(f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã. –ò–∑–º–µ–Ω–µ–Ω–æ: {updated_count}/{len(REPOS)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")

        # –î–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
        for repo, data in self.priorities.items():
            status = "üî¥" if data['priority_score'] >= PRIORITY_THRESHOLD_HIGH else \
                "üü¢" if data['priority_score'] <= PRIORITY_THRESHOLD_LOW else "üü°"
            failures = data.get('consecutive_failures', 0)
            failure_info = f" ‚ö†Ô∏è{failures}" if failures > 0 else ""
            logger.info(
                f"{status} {repo}: –∏–Ω—Ç–µ—Ä–≤–∞–ª {data['check_interval']} –º–∏–Ω, "
                f"–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç {data['priority_score']:.3f}{failure_info}"
            )

    def get_priority_stats(self) -> Dict:
        stats = {
            'high_priority': 0,
            'medium_priority': 0,
            'low_priority': 0,
            'failing_repos': 0,
            'total_repos': len(REPOS),
            'average_interval': 0,
            'total_checks': 0,
            'total_updates': 0
        }

        total_interval = 0
        for repo in REPOS:
            priority_data = self.get_priority(repo)
            score = priority_data['priority_score']
            failures = priority_data.get('consecutive_failures', 0)

            if score >= PRIORITY_THRESHOLD_HIGH:
                stats['high_priority'] += 1
            elif score <= PRIORITY_THRESHOLD_LOW:
                stats['low_priority'] += 1
            else:
                stats['medium_priority'] += 1

            if failures > 3:
                stats['failing_repos'] += 1

            total_interval += priority_data['check_interval']
            stats['total_checks'] += priority_data.get('total_checks', 0)
            stats['total_updates'] += priority_data.get('update_count', 0)

        stats['average_interval'] = round(total_interval / len(REPOS), 1)
        return stats

# --- –ö–õ–ê–°–° –î–õ–Ø –ö–≠–®–ò–†–û–í–ê–ù–ò–Ø ---
class GitHubCache:
    """–ö—ç—à –¥–ª—è GitHub API –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤"""
    
    def __init__(self, cache_file: str, max_age_hours: int = 2):
        self.cache_file = cache_file
        self.max_age_seconds = max_age_hours * 3600
        self.cache = {}
        self.load_cache()
    
    def load_cache(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                logger.info(f"–ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω: {len(self.cache)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")
            self.cache = {}
    
    def save_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à –≤ —Ñ–∞–π–ª"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")
    
    def get(self, key: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞ –µ—Å–ª–∏ –æ–Ω–æ –Ω–µ —É—Å—Ç–∞—Ä–µ–ª–æ"""
        if key in self.cache:
            cache_entry = self.cache[key]
            if time.time() - cache_entry['timestamp'] < self.max_age_seconds:
                return cache_entry['data']
            else:
                # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à—É—é –∑–∞–ø–∏—Å—å
                del self.cache[key]
        return None
    
    def set(self, key: str, data: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫—ç—à"""
        self.cache[key] = {
            'data': data,
            'timestamp': time.time()
        }
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
        if len(self.cache) > 100:
            # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
            oldest_keys = sorted(self.cache.keys(), 
                               key=lambda k: self.cache[k]['timestamp'])[:20]
            for old_key in oldest_keys:
                del self.cache[old_key]
    
    def cleanup(self):
        """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏"""
        current_time = time.time()
        expired_keys = [
            key for key, entry in self.cache.items()
            if current_time - entry['timestamp'] > self.max_age_seconds
        ]
        for key in expired_keys:
            del self.cache[key]
        if expired_keys:
            logger.info(f"–û—á–∏—â–µ–Ω–æ {len(expired_keys)} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π –∫—ç—à–∞")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞
github_cache = GitHubCache(STATE_FILE)

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ö–õ–ê–°–°–´ –î–õ–Ø –£–ü–†–ê–í–õ–ï–ù–ò–Ø –î–ê–ù–ù–´–ú–ò ---

class StatisticsManager:
    def __init__(self):
        self.stats_file = STATISTICS_FILE
        self.stats = self._load_stats()

    def _load_stats(self) -> Dict:
        if os.path.exists(self.stats_file):
            try:
                with open(self.stats_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        
        return {
            'total_checks': 0,
            'total_releases_found': 0,
            'total_notifications_sent': 0,
            'errors_count': 0,
            'start_time': datetime.now(timezone.utc).isoformat(),
            'last_activity': None,
            'repo_stats': {repo: {'checks': 0, 'releases': 0} for repo in REPOS}
        }

    def _save_stats(self):
        try:
            self.stats['last_activity'] = datetime.now(timezone.utc).isoformat()
            with open(self.stats_file, 'w', encoding='utf-8') as f:
                json.dump(self.stats, f, indent=2, ensure_ascii=False)
        except IOError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

    def increment_checks(self, repo_name: str = None):
        self.stats['total_checks'] += 1
        if repo_name and repo_name in self.stats['repo_stats']:
            self.stats['repo_stats'][repo_name]['checks'] += 1
        self._save_stats()

    def increment_releases(self, repo_name: str = None):
        self.stats['total_releases_found'] += 1
        if repo_name and repo_name in self.stats['repo_stats']:
            self.stats['repo_stats'][repo_name]['releases'] += 1
        self._save_stats()

    def increment_notifications(self):
        self.stats['total_notifications_sent'] += 1
        self._save_stats()

    def increment_errors(self):
        self.stats['errors_count'] += 1
        self._save_stats()

    def get_uptime(self) -> str:
        try:
            start_time = datetime.fromisoformat(self.stats['start_time'])
            uptime = datetime.now(timezone.utc) - start_time
            days = uptime.days
            hours, remainder = divmod(uptime.seconds, 3600)
            minutes, _ = divmod(remainder, 60)
            return f"{days}–¥ {hours}—á {minutes}–º"
        except:
            return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

class UserManager:
    def __init__(self):
        self.users_file = USERS_FILE
        self.users_data = self._load_users()

    def _load_users(self) -> Dict[int, Dict]:
        if os.path.exists(self.users_file):
            try:
                with open(self.users_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    if isinstance(data, list):
                        return {user_id: self._create_user_data() for user_id in data}
                    elif isinstance(data, dict):
                        for user_id, user_data in data.items():
                            if not isinstance(user_data, dict):
                                data[user_id] = self._create_user_data()
                            else:
                                default_data = self._create_user_data()
                                for field, default_value in default_data.items():
                                    if field not in user_data:
                                        user_data[field] = default_value
                        return {int(k): v for k, v in data.items()}
                    
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")
        
        return {}

    def _create_user_data(self) -> Dict:
        return {
            'joined_at': datetime.now(timezone.utc).isoformat(),
            'last_activity': None,
            'notifications_received': 0,
            'commands_used': 0,
            'is_active': True
        }

    def _save_users(self):
        try:
            if os.path.exists(self.users_file):
                backup_file = f"{self.users_file}.bak"
                shutil.copy2(self.users_file, backup_file)

            with open(self.users_file, 'w', encoding='utf-8') as f:
                json.dump(self.users_data, f, ensure_ascii=False, indent=2)
        except IOError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")

    def add_user(self, user_id: int, username: str = None):
        if user_id not in self.users_data:
            self.users_data[user_id] = self._create_user_data()
            if username:
                self.users_data[user_id]['username'] = username
            self._save_users()
            logger.info(f"–ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_id} ({username})")
        else:
            self.users_data[user_id]['last_activity'] = datetime.now(timezone.utc).isoformat()
            if username and 'username' not in self.users_data[user_id]:
                self.users_data[user_id]['username'] = username
                self._save_users()

    def record_activity(self, user_id: int, activity_type: str = 'command'):
        if user_id in self.users_data:
            self.users_data[user_id]['last_activity'] = datetime.now(timezone.utc).isoformat()
            if activity_type == 'command':
                self.users_data[user_id]['commands_used'] += 1
            elif activity_type == 'notification':
                self.users_data[user_id]['notifications_received'] += 1
            self._save_users()

    def get_users(self) -> Set[int]:
        return set(self.users_data.keys())

    def get_active_users(self, days: int = 30) -> Set[int]:
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)
        active_users = set()
        
        for user_id, user_data in self.users_data.items():
            if user_data.get('is_active', True):
                last_activity = user_data.get('last_activity')
                if last_activity:
                    try:
                        activity_date = datetime.fromisoformat(last_activity)
                        if activity_date >= cutoff_date:
                            active_users.add(user_id)
                    except:
                        active_users.add(user_id)
                else:
                    active_users.add(user_id)
        
        return active_users

    def get_count(self) -> int:
        return len(self.users_data)

    def get_stats(self) -> Dict:
        active_users = len(self.get_active_users(30))
        total_commands = sum(data.get('commands_used', 0) for data in self.users_data.values())
        total_notifications = sum(data.get('notifications_received', 0) for data in self.users_data.values())
        
        return {
            'total_users': len(self.users_data),
            'active_users_30d': active_users,
            'total_commands': total_commands,
            'total_notifications': total_notifications
        }

class ReleaseStateManager:
    def __init__(self):
        self.state_file = STATE_FILE
        self.state = self._load_state()

    def _load_state(self) -> Dict[str, str]:
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")
                self._backup_corrupted_file()
        return {}

    def _backup_corrupted_file(self):
        try:
            if os.path.exists(self.state_file):
                backup_name = f"state_corrupted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                backup_path = os.path.join(BACKUP_DIR, backup_name)
                shutil.copy2(self.state_file, backup_path)
                logger.warning(f"–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: {backup_path}")
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")

    def _save_state(self):
        try:
            if os.path.exists(self.state_file):
                backup_file = f"{self.state_file}.bak"
                shutil.copy2(self.state_file, backup_file)

            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(self.state, f, ensure_ascii=False, indent=2)
        except IOError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")

    def update_tag(self, repo: str, tag: str):
        self.state[repo] = tag
        self._save_state()
        logger.debug(f"–û–±–Ω–æ–≤–ª–µ–Ω —Ç–µ–≥ –¥–ª—è {repo}: {tag}")

    def get_last_tag(self, repo: str) -> Optional[str]:
        return self.state.get(repo)

class FilterManager:
    def __init__(self):
        self.filters_file = FILTERS_FILE
        self.filters = self._load_filters()

    def _load_filters(self) -> Dict[str, List[str]]:
        if os.path.exists(self.filters_file):
            try:
                with open(self.filters_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤: {e}")
        return {}

    def _save_filters(self):
        try:
            if os.path.exists(self.filters_file):
                backup_file = f"{self.filters_file}.bak"
                shutil.copy2(self.filters_file, backup_file)

            with open(self.filters_file, 'w', encoding='utf-8') as f:
                json.dump(self.filters, f, ensure_ascii=False, indent=2)
        except IOError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤: {e}")

    def set_filters(self, user_id: str, keywords: List[str]):
        normalized_keywords = [keyword.strip().lower() for keyword in keywords if keyword.strip()]
        if normalized_keywords:
            self.filters[user_id] = normalized_keywords
            self._save_filters()
            logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {normalized_keywords}")

    def get_filters(self, user_id: str) -> List[str]:
        return self.filters.get(user_id, [])

    def clear_filters(self, user_id: str):
        if user_id in self.filters:
            del self.filters[user_id]
            self._save_filters()
            logger.info(f"–û—á–∏—â–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")

    def get_users_with_filters_count(self) -> int:
        return len(self.filters)

    def get_stats(self) -> Dict:
        total_filters = len(self.filters)
        avg_keywords = 0
        if total_filters > 0:
            total_keywords = sum(len(keywords) for keywords in self.filters.values())
            avg_keywords = round(total_keywords / total_filters, 1)
        
        return {
            'users_with_filters': total_filters,
            'average_keywords_per_user': avg_keywords
        }

class ReleaseHistoryManager:
    def __init__(self):
        self.history_file = HISTORY_FILE
        self.history = self._load_history()

    def _load_history(self) -> List[Dict]:
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        return []

    def _save_history(self):
        try:
            cutoff_date = datetime.now(timezone.utc) - timedelta(days=HISTORY_DAYS)
            filtered_history = [
                rel for rel in self.history
                if datetime.fromisoformat(rel['published_at'].replace('Z', '+00:00')) >= cutoff_date
            ]

            if os.path.exists(self.history_file):
                backup_file = f"{self.history_file}.bak"
                shutil.copy2(self.history_file, backup_file)

            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(filtered_history, f, ensure_ascii=False, indent=2)
            
            removed_count = len(self.history) - len(filtered_history)
            if removed_count > 0:
                logger.info(f"–£–¥–∞–ª–µ–Ω–æ {removed_count} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏")
                
            self.history = filtered_history
        except IOError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")

    def add_release(self, repo_name: str, release: Dict):
        exists = any(
            rel['repo_name'] == repo_name and rel['tag_name'] == release.get('tag_name')
            for rel in self.history
        )

        if not exists:
            history_entry = {
                'repo_name': repo_name,
                'tag_name': release.get('tag_name'),
                'name': release.get('name'),
                'published_at': release.get('published_at'),
                'body': release.get('body', ''),
                'assets': release.get('assets', []),
                'added_to_history': datetime.now(timezone.utc).isoformat()
            }
            self.history.append(history_entry)
            self._save_history()
            logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω —Ä–µ–ª–∏–∑ –≤ –∏—Å—Ç–æ—Ä–∏—é: {repo_name} {release.get('tag_name')}")
            return True
        return False

    def get_releases_by_date(self, target_date) -> List[Dict]:
        logger.info(f"–ü–æ–∏—Å–∫ —Ä–µ–ª–∏–∑–æ–≤ –∑–∞ –¥–∞—Ç—É: {target_date}")

        result = []
        for rel in self.history:
            try:
                pub_date_str = rel['published_at']
                if pub_date_str.endswith('Z'):
                    pub_date_str = pub_date_str[:-1] + '+00:00'

                pub_date = datetime.fromisoformat(pub_date_str).astimezone(timezone.utc).date()
                
                if pub_date == target_date:
                    result.append(rel)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞—Ç—ã —Ä–µ–ª–∏–∑–∞ {rel['repo_name']} {rel['tag_name']}: {e}")

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(result)} —Ä–µ–ª–∏–∑–æ–≤ –∑–∞ –¥–∞—Ç—É {target_date}")
        return sorted(result, key=lambda x: x['published_at'], reverse=True)

    def get_recent_releases(self, days: int = 3) -> List[Dict]:
        cutoff_date = datetime.now(timezone.utc).date() - timedelta(days=days)
        releases = []
        
        for rel in self.history:
            try:
                pub_date_str = rel['published_at']
                if pub_date_str.endswith('Z'):
                    pub_date_str = pub_date_str[:-1] + '+00:00'
                
                pub_date = datetime.fromisoformat(pub_date_str).date()
                if pub_date >= cutoff_date:
                    releases.append(rel)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç—ã —Ä–µ–ª–∏–∑–∞: {e}")
                continue
        
        return sorted(releases, key=lambda x: x['published_at'], reverse=True)

    def get_count(self) -> int:
        return len(self.history)

    def get_stats(self) -> Dict:
        if not self.history:
            return {'total_releases': 0, 'releases_by_repo': {}, 'releases_last_7_days': 0}
        
        releases_by_repo = {}
        recent_releases = 0
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=7)
        
        for rel in self.history:
            repo = rel['repo_name']
            releases_by_repo[repo] = releases_by_repo.get(repo, 0) + 1
            
            try:
                pub_date_str = rel['published_at']
                if pub_date_str.endswith('Z'):
                    pub_date_str = pub_date_str[:-1] + '+00:00'
                pub_date = datetime.fromisoformat(pub_date_str)
                if pub_date >= cutoff_date:
                    recent_releases += 1
            except:
                pass
        
        return {
            'total_releases': len(self.history),
            'releases_by_repo': releases_by_repo,
            'releases_last_7_days': recent_releases
        }

# --- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–ï–ù–ï–î–ñ–ï–†–û–í ---
statistics_manager = StatisticsManager()
user_manager = UserManager()
state_manager = ReleaseStateManager()
filter_manager = FilterManager()
history_manager = ReleaseHistoryManager()
priority_manager = RepositoryPriorityManager()

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –ò–ù–§–û–†–ú–ê–¶–ò–ò –û –†–ï–õ–ò–ó–ê–• ---
async def fetch_release_optimized(session: ClientSession, repo_name: str) -> Tuple[Optional[Dict], float]:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Ä–µ–ª–∏–∑–µ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    cache_key = f"release_{repo_name}"
    cached_data = github_cache.get(cache_key)
    if cached_data:
        logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {repo_name}")
        return cached_data, 0.0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
    # await resource_manager.check_memory_usage() # resource_manager is not defined in this file
    
    api_url = f"https://api.github.com/repos/{repo_name}/releases/latest"
    headers = {'User-Agent': 'GitHub-Release-Monitor-Bot-Optimized'}
    
    if GITHUB_TOKEN:
        headers['Authorization'] = f'token {GITHUB_TOKEN}'

    start_time = time.time()
    
    # async with resource_manager.request_semaphore: # resource_manager is not defined in this file
    #     for attempt in range(MAX_RETRIES):
    #         try:
    #             async with session.get(api_url, headers=headers) as response:
    #                 response_time = time.time() - start_time
                    
    #                 if response.status == 200:
    #                     data = await response.json()
                        
    #                     # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    #                     github_cache.set(cache_key, data)
                        
    #                     logger.debug(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {repo_name} –∑–∞ {response_time:.2f}—Å")
    #                     return data, response_time
                        
    #                 elif response.status == 403:
    #                     # Rate limit - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏
    #                     logger.warning(f"Rate limit –¥–ª—è {repo_name}")
    #                     return None, response_time
                        
    #                 elif response.status == 404:
    #                     logger.warning(f"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {repo_name}")
    #                     return None, response_time
                        
    #                 else:
    #                     logger.warning(f"–°—Ç–∞—Ç—É—Å {response.status} –¥–ª—è {repo_name}")
    #                     if attempt < MAX_RETRIES - 1:
    #                         await asyncio.sleep(RETRY_DELAY)
    #                         continue
    #                     return None, response_time
                        
    #         except asyncio.TimeoutError:
    #             logger.warning(f"Timeout –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ {repo_name}")
    #         except Exception as e:
    #             logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {repo_name}: {e}")
                
    #         if attempt < MAX_RETRIES - 1:
    #             await asyncio.sleep(RETRY_DELAY)
    
    response_time = time.time() - start_time
    return None, response_time

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –†–ï–ü–û–ó–ò–¢–û–†–ò–ï–í –° –ü–†–ò–û–†–ò–¢–ï–¢–ê–ú–ò ---
async def check_repositories_optimized(bot: Bot):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å —É—á–µ—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤"""
    logger.info("üîÑ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ—Å—É—Ä—Å—ã
    # await resource_manager.check_memory_usage() # resource_manager is not defined in this file
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if priority_manager.should_update_priorities():
        logger.info("üìä –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")
        priority_manager.update_priorities(history_manager)
    
    current_time = datetime.now(timezone.utc)
    repos_to_check = []
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
    for repo_name in REPOS:
        priority_data = priority_manager.get_priority(repo_name)
        check_interval = priority_data['check_interval']
        last_check = priority_data.get('last_check')

        should_check = False
        if not last_check:
            should_check = True
            logger.debug(f"üì¶ {repo_name}: –ø–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
        else:
            try:
                last_check_time = datetime.fromisoformat(last_check)
                time_since_check = current_time - last_check_time
                
                if time_since_check >= timedelta(minutes=check_interval):
                    should_check = True
                    logger.debug(f"üì¶ {repo_name}: –ø—Ä–æ—à–ª–æ {time_since_check}, –∏–Ω—Ç–µ—Ä–≤–∞–ª {check_interval} –º–∏–Ω")
                else:
                    remaining = timedelta(minutes=check_interval) - time_since_check
                    logger.debug(f"üì¶ {repo_name}: –µ—â—ë {remaining} –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è {repo_name}: {e}")
                should_check = True

        if should_check:
            repos_to_check.append(repo_name)
    
    if not repos_to_check:
        logger.info("–ù–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        return
    
    logger.info(f"üìã –ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {len(repos_to_check)} –∏–∑ {len(REPOS)} —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø–∞–∫–µ—Ç–∞–º–∏
    for i in range(0, len(repos_to_check), BATCH_SIZE):
        batch = repos_to_check[i:i + BATCH_SIZE]
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è –ø–∞–∫–µ—Ç–∞
        # async with resource_manager.get_session() as session: # resource_manager is not defined in this file
        async with ClientSession() as session: # Simplified for now, assuming a session manager exists or is needed
            tasks = []
            for repo_name in batch:
                task = check_single_repo_optimized(bot, session, repo_name)
                tasks.append(task)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞–∫–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for repo_name, result in zip(batch, results):
                if isinstance(result, Exception):
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {repo_name}: {result}")
                elif result:
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è {repo_name}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                priority_data = priority_manager.get_priority(repo_name)
                priority_data['last_check'] = current_time.isoformat()
                priority_manager._save_priorities()
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
        if i + BATCH_SIZE < len(repos_to_check):
            await asyncio.sleep(5)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à
    github_cache.save_cache()
    
    logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

async def check_single_repo_optimized(bot: Bot, session: ClientSession, repo_name: str) -> bool:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å —É—á–µ—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤"""
    try:
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–≤–µ—Ä–æ–∫
        priority_manager.record_check(repo_name, True, 0.0)
        
        release, response_time = await fetch_release_optimized(session, repo_name)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≤–µ—Ä–∫–µ
        success = release is not None
        priority_manager.record_check(repo_name, success, response_time)

        if not release:
            logger.warning(f"‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ —Ä–µ–ª–∏–∑–∞—Ö –¥–ª—è {repo_name}")
            return False

        current_tag = release.get('tag_name')
        if not current_tag:
            logger.warning(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ç–µ–≥ –≤ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–ª–∏–∑–∞ –¥–ª—è {repo_name}")
            return False

        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–æ–≤—ã–µ —Ç–µ–≥–∏
        # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False
        
        return False

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {repo_name}: {e}")
        priority_manager.record_check(repo_name, False, 0.0)
        return False

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–õ–ê–ù–ò–†–û–í–©–ò–ö ---
def setup_optimized_scheduler(scheduler: AsyncIOScheduler, bot: Bot):
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è —Å–ª–∞–±–æ–≥–æ VPS —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏"""
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç (—Å —É—á–µ—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤)
    scheduler.add_job(
        check_repositories_optimized,
        'interval',
        minutes=30,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 15 –¥–æ 30
        kwargs={'bot': bot},
        id='repositories_check_optimized',
        max_instances=1,
        coalesce=True
    )
    
    # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∫–∞–∂–¥—ã–µ 4 —á–∞—Å–∞
    scheduler.add_job(
        lambda: github_cache.cleanup(),
        'interval',
        hours=4,
        id='cache_cleanup',
        max_instances=1
    )
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –∫–∞–∂–¥—ã–µ 2 —á–∞—Å–∞
    # scheduler.add_job( # resource_manager is not defined in this file
    #     resource_manager.check_memory_usage,
    #     'interval',
    #     hours=2,
    #     id='resource_check',
    #     max_instances=1
    # )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞ –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
    scheduler.add_job(
        github_cache.save_cache,
        'interval',
        hours=6,
        id='cache_save',
        max_instances=1
    )

# --- –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ---
async def main_optimized():
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–ª–∞–±–æ–≥–æ VPS —Å —Å–∏—Å—Ç–µ–º–æ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤"""
    print("=" * 50)
    print("üöÄ –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –ë–û–¢–ê –° –ü–†–ò–û–†–ò–¢–ï–¢–ê–ú–ò –î–õ–Ø –°–õ–ê–ë–û–ì–û VPS")
    print("=" * 50)

    if not BOT_TOKEN:
        logger.error("‚ùå BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–æ—Ç–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏...")
    print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–æ—Ç–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏...")

    bot = Bot(token=BOT_TOKEN)
    dp = Dispatcher()

    logger.info("‚è∞ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏...")
    print("‚è∞ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏...")
    
    scheduler = AsyncIOScheduler(timezone="UTC")
    setup_optimized_scheduler(scheduler, bot)
    
    scheduler.start()
    logger.info("‚è∞ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ –∑–∞–ø—É—â–µ–Ω")
    print("‚è∞ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ –∑–∞–ø—É—â–µ–Ω")

    print(f"\nüìä –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –° –ü–†–ò–û–†–ò–¢–ï–¢–ê–ú–ò:")
    print(f"‚îú‚îÄ‚îÄ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(REPOS)}")
    print(f"‚îú‚îÄ‚îÄ –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {MIN_CHECK_INTERVAL_MINUTES}-{MAX_CHECK_INTERVAL_MINUTES} –º–∏–Ω")
    print(f"‚îú‚îÄ‚îÄ –ú–∞–∫—Å. –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {MAX_CONCURRENT_REQUESTS}")
    print(f"‚îú‚îÄ‚îÄ –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞: {REQUEST_TIMEOUT} —Å–µ–∫")
    print(f"‚îú‚îÄ‚îÄ –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞: {BATCH_SIZE}")
    print(f"‚îú‚îÄ‚îÄ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ: –≤–∫–ª—é—á–µ–Ω–æ")
    print(f"‚îî‚îÄ‚îÄ –°–∏—Å—Ç–µ–º–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤: –∞–∫—Ç–∏–≤–Ω–∞")

    try:
        await dp.start_polling(bot, skip_updates=True)
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        print("\n‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞...")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        print("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        
        scheduler.shutdown(wait=True)
        github_cache.save_cache()
        await bot.session.close()
        
        logger.info("‚úÖ –ë–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("‚úÖ –ë–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# --- –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–ò–í–ù–´–ï –ö–û–ú–ê–ù–î–´ ---
async def stats_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /stats"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    user_manager.record_activity(message.from_user.id, 'command')

    if message.from_user.id != ADMIN_ID:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    logger.info(f"üìä –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")

    user_stats = user_manager.get_stats()
    filter_stats = filter_manager.get_stats()
    history_stats = history_manager.get_stats()
    priority_stats = priority_manager.get_priority_stats()
    
    uptime = statistics_manager.get_uptime()
    
    stats_message = (
        f"üìä *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–æ—Ç–∞*\n\n"
        
        f"üë• *–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏:*\n"
        f"‚Ä¢ –í—Å–µ–≥–æ: {user_stats['total_users']}\n"
        f"‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö (30 –¥–Ω–µ–π): {user_stats['active_users_30d']}\n"
        f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∫–æ–º–∞–Ω–¥: {user_stats['total_commands']}\n"
        f"‚Ä¢ –ü–æ–ª—É—á–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: {user_stats['total_notifications']}\n\n"
        
        f"üîç *–§–∏–ª—å—Ç—Ä—ã:*\n"
        f"‚Ä¢ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏: {filter_stats['users_with_filters']}\n"
        f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Å–ª–æ–≤ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {filter_stats['average_keywords_per_user']}\n\n"
        
        f"üì¶ *–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏:*\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è: {priority_stats['total_repos']}\n"
        f"‚Ä¢ –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority_stats['high_priority']} üî¥\n"
        f"‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority_stats['medium_priority']} üü°\n"
        f"‚Ä¢ –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority_stats['low_priority']} üü¢\n"
        f"‚Ä¢ –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ: {priority_stats['failing_repos']} ‚ö†Ô∏è\n"
        f"‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: {priority_stats['average_interval']} –º–∏–Ω\n\n"
        
        f"üìà *–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å:*\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–æ–∫: {statistics_manager.stats['total_checks']}\n"
        f"‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–∏–∑–æ–≤: {statistics_manager.stats['total_releases_found']}\n"
        f"‚Ä¢ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: {statistics_manager.stats['total_notifications_sent']}\n"
        f"‚Ä¢ –û—à–∏–±–æ–∫: {statistics_manager.stats['errors_count']}\n\n"
        
        f"üìÖ *–ò—Å—Ç–æ—Ä–∏—è:*\n"
        f"‚Ä¢ –†–µ–ª–∏–∑–æ–≤ –≤ –±–∞–∑–µ: {history_stats['total_releases']}\n"
        f"‚Ä¢ –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π: {history_stats['releases_last_7_days']}\n\n"
        
        f"‚öôÔ∏è *VPS –ø—Ä–æ—Ñ–∏–ª—å:* {VPS_PROFILE}\n"
        f"‚è±Ô∏è *–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã:* {uptime}\n"
        f"üîÑ *–ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å:* {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    )

    await message.answer(stats_message, parse_mode="Markdown")

async def priority_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /priority"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    user_manager.record_activity(message.from_user.id, 'command')

    if message.from_user.id != ADMIN_ID:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    logger.info(f"üìä –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")

    try:
        priority_manager.initialize_priorities()
        logger.info("‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å –ë–î –¥–ª—è –∫–æ–º–∞–Ω–¥—ã /priority")
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Å –ë–î: {e}")

    priority_info = "üìä *–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤:*\n\n"

    if priority_manager.db_synced:
        priority_info += "üóÑÔ∏è *–ò—Å—Ç–æ—á–Ω–∏–∫:* –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö Supabase\n\n"
    else:
        priority_info += "‚ö†Ô∏è *–ò—Å—Ç–æ—á–Ω–∏–∫:* –õ–æ–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ë–î –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)\n\n"

    sorted_repos = sorted(
        REPOS, 
        key=lambda repo: priority_manager.get_priority(repo)['priority_score'],
        reverse=True
    )

    for repo in sorted_repos:
        priority_data = priority_manager.get_priority(repo)
        interval = priority_data['check_interval']
        score = priority_data['priority_score']
        failures = priority_data.get('consecutive_failures', 0)
        total_checks = priority_data.get('total_checks', 0)
        updates = priority_data.get('update_count', 0)

        if score >= PRIORITY_THRESHOLD_HIGH:
            status = "üî¥"
            status_text = "–í—ã—Å–æ–∫–∏–π"
        elif score <= PRIORITY_THRESHOLD_LOW:
            status = "üü¢"
            status_text = "–ù–∏–∑–∫–∏–π"
        else:
            status = "üü°"
            status_text = "–°—Ä–µ–¥–Ω–∏–π"

        problem_indicator = ""
        if failures > 3:
            problem_indicator = f" ‚ö†Ô∏è{failures}"

        repo_short = repo.split('/')[-1]
        
        priority_info += (
            f"{status} *{repo_short}*\n"
            f"   ‚îî {status_text} –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç ({score:.2f})\n"
            f"   ‚îî –ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval} –º–∏–Ω{problem_indicator}\n"
            f"   ‚îî –û–±–Ω–æ–≤–ª–µ–Ω–∏–π: {updates}, –ø—Ä–æ–≤–µ—Ä–æ–∫: {total_checks}\n\n"
        )

    priority_info += (
        f"üìù *–õ–µ–≥–µ–Ω–¥–∞:*\n"
        f"üî¥ –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (‚â•{PRIORITY_THRESHOLD_HIGH}) ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ {MIN_CHECK_INTERVAL_MINUTES} –º–∏–Ω\n"
        f"üü° –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é\n"
        f"üü¢ –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (‚â§{PRIORITY_THRESHOLD_LOW}) ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ {MAX_CHECK_INTERVAL_MINUTES//60} —á\n"
        f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º\n\n"
        f"‚öôÔ∏è *VPS –ø—Ä–æ—Ñ–∏–ª—å:* {VPS_PROFILE}"
    )

    await message.answer(priority_info, parse_mode="Markdown")

async def sync_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /sync - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –ë–î"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    user_manager.record_activity(message.from_user.id, 'command')

    if message.from_user.id != ADMIN_ID:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    logger.info(f"üîÑ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é —Å –ë–î")

    try:
        sync_msg = await message.answer("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö...")
        
        if not priority_manager.supabase_manager:
            await sync_msg.edit_text("‚ùå Supabase –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è.", parse_mode="Markdown")
            return
        
        priority_manager.initialize_priorities()
        priority_stats = priority_manager.get_priority_stats()
        
        sync_status = "‚úÖ" if priority_manager.db_synced else "‚ö†Ô∏è"
        sync_text = "–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ" if priority_manager.db_synced else "–ù–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ"
        
        success_message = (
            f"{sync_status} *–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!*\n\n"
            f"üìä *–°—Ç–∞—Ç—É—Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤:*\n"
            f"‚Ä¢ –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority_stats['high_priority']} üî¥\n"
            f"‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority_stats['medium_priority']} üü°\n"
            f"‚Ä¢ –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority_stats['low_priority']} üü¢\n"
            f"‚Ä¢ –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ: {priority_stats['failing_repos']} ‚ö†Ô∏è\n\n"
            f"üóÑÔ∏è *–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:*\n"
            f"‚Ä¢ –°—Ç–∞—Ç—É—Å: {sync_text}\n"
            f"‚Ä¢ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {priority_stats['total_repos']}\n"
            f"‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: {priority_stats['average_interval']} –º–∏–Ω\n\n"
            f"üîÑ *–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:* {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        )
        
        await sync_msg.edit_text(success_message, parse_mode="Markdown")
        logger.info("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –ë–î –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        error_message = f"‚ùå *–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:* {str(e)}"
        await sync_msg.edit_text(error_message, parse_mode="Markdown")
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å –ë–î: {e}")

async def pstats_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /pstats"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    user_manager.record_activity(message.from_user.id, 'command')

    if message.from_user.id != ADMIN_ID:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    logger.info(f"üìà –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤")

    stats = priority_manager.get_priority_stats()
    
    if stats['total_repos'] > 0:
        high_ratio = stats['high_priority'] / stats['total_repos'] * 100
        low_ratio = stats['low_priority'] / stats['total_repos'] * 100
        medium_ratio = stats['medium_priority'] / stats['total_repos'] * 100
    else:
        high_ratio = low_ratio = medium_ratio = 0

    last_update = priority_manager.last_priority_update
    if last_update:
        update_text = last_update.strftime('%Y-%m-%d %H:%M UTC')
        time_since = datetime.now(timezone.utc) - last_update
        hours_since = time_since.total_seconds() / 3600
    else:
        update_text = "–ï—â–µ –Ω–µ –æ–±–Ω–æ–≤–ª—è–ª–æ—Å—å"
        hours_since = 0

    stats_message = (
        f"üìà *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤*\n\n"
        
        f"üìä *–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤:*\n"
        f"üî¥ –í—ã—Å–æ–∫–∏–π: {stats['high_priority']} ({high_ratio:.1f}%)\n"
        f"üü° –°—Ä–µ–¥–Ω–∏–π: {stats['medium_priority']} ({medium_ratio:.1f}%)\n"
        f"üü¢ –ù–∏–∑–∫–∏–π: {stats['low_priority']} ({low_ratio:.1f}%)\n"
        f"üì¶ –í—Å–µ–≥–æ: {stats['total_repos']}\n\n"
        
        f"‚ö†Ô∏è *–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏:* {stats['failing_repos']}\n"
        f"üìä *–°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏:* {stats['average_interval']} –º–∏–Ω\n\n"
        
        f"üìà *–û–±—â–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å:*\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–æ–∫: {stats['total_checks']:,}\n"
        f"‚Ä¢ –í—Å–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π: {stats['total_updates']:,}\n\n"
        
        f"üîÑ *–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:*\n"
        f"‚Ä¢ –î–∞—Ç–∞: {update_text}\n"
        f"‚Ä¢ –ü—Ä–æ—à–ª–æ –≤—Ä–µ–º–µ–Ω–∏: {hours_since:.1f} —á\n\n"
        
        f"‚öôÔ∏è *–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∏—Å—Ç–µ–º—ã:*\n"
        f"‚Ä¢ –ú–∏–Ω. –∏–Ω—Ç–µ—Ä–≤–∞–ª: {MIN_CHECK_INTERVAL_MINUTES} –º–∏–Ω\n"
        f"‚Ä¢ –ú–∞–∫—Å. –∏–Ω—Ç–µ—Ä–≤–∞–ª: {MAX_CHECK_INTERVAL_MINUTES//60} —á\n"
        f"‚Ä¢ –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: {PRIORITY_UPDATE_DAYS} –¥–Ω–µ–π\n"
        f"‚Ä¢ –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: ‚â•{PRIORITY_THRESHOLD_HIGH}\n"
        f"‚Ä¢ –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: ‚â§{PRIORITY_THRESHOLD_LOW}\n\n"
        f"üîß *VPS –ø—Ä–æ—Ñ–∏–ª—å:* {VPS_PROFILE}"
    )

    await message.answer(stats_message, parse_mode="Markdown")

async def checkall_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /checkall"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    user_manager.record_activity(message.from_user.id, 'command')

    if message.from_user.id != ADMIN_ID:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    logger.info(f"üîÑ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤")

    status_message = await message.answer(
        "üîÑ *–ó–∞–ø—É—Å–∫ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Å–µ—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...*\n\n"
        "‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.",
        parse_mode="Markdown"
    )

    try:
        start_time = datetime.now()
        await check_all_repositories(message.bot)
        end_time = datetime.now()
        
        duration = (end_time - start_time).total_seconds()
        
        await status_message.edit_text(
            f"‚úÖ *–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞*\n\n"
            f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f} —Å–µ–∫\n"
            f"üì¶ –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(REPOS)}\n"
            f"üïí –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {end_time.strftime('%H:%M:%S')}\n\n"
            f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ –ª–æ–≥–∏. "
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /stats –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.",
            parse_mode="Markdown"
        )
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
        await status_message.edit_text(
            f"‚ùå *–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤*\n\n"
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: `{str(e)[:200]}`\n\n"
            f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.",
            parse_mode="Markdown"
        )

async def backup_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /backup –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    user_manager.record_activity(message.from_user.id, 'command')

    if message.from_user.id != ADMIN_ID:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    logger.info(f"üíæ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä —Å–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏")

    try:
        backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_folder = os.path.join(BACKUP_DIR, f"backup_{backup_timestamp}")
        os.makedirs(backup_folder, exist_ok=True)

        files_to_backup = [
            STATE_FILE,
            FILTERS_FILE,
            HISTORY_FILE,
            USERS_FILE,
            STATISTICS_FILE
        ]

        backed_up_files = []
        
        for file_path in files_to_backup:
            if os.path.exists(file_path):
                backup_path = os.path.join(backup_folder, os.path.basename(file_path))
                shutil.copy2(file_path, backup_path)
                backed_up_files.append(os.path.basename(file_path))

        if backed_up_files:
            await message.answer(
                f"üíæ *–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞*\n\n"
                f"üìÅ –ü–∞–ø–∫–∞: `{backup_folder}`\n"
                f"üìã –§–∞–π–ª—ã: {', '.join(backed_up_files)}\n"
                f"üïí –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                f"‚úÖ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {len(backed_up_files)}",
                parse_mode="Markdown"
            )
        else:
            await message.answer(
                "‚ö†Ô∏è *–í–Ω–∏–º–∞–Ω–∏–µ*\n\n"
                "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è.\n"
                "–í–æ–∑–º–æ–∂–Ω–æ, –±–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤–ø–µ—Ä–≤—ã–µ –∏–ª–∏ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.",
                parse_mode="Markdown"
            )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
        await message.answer(
            f"‚ùå *–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏*\n\n"
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: `{str(e)[:200]}`\n\n"
            f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ.",
            parse_mode="Markdown"
        )

# --- –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –°–õ–£–ñ–ï–ë–ù–´–ï –ö–û–ú–ê–ù–î–´ ---
async def debug_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /debug –¥–ª—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    user_manager.record_activity(message.from_user.id, 'command')

    if message.from_user.id != ADMIN_ID:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    logger.info(f"üêõ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")

    try:
        import psutil
        import sys
        
        memory_info = psutil.virtual_memory()
        disk_info = psutil.disk_usage('.')
        
        debug_info = (
            f"üêõ *–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è*\n\n"
            
            f"üíª *–°–∏—Å—Ç–µ–º–∞:*\n"
            f"‚Ä¢ Python: {sys.version.split()[0]}\n"
            f"‚Ä¢ –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: {sys.platform}\n"
            f"‚Ä¢ –û–ó–£: {memory_info.percent}% –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ\n"
            f"‚Ä¢ –î–∏—Å–∫: {disk_info.percent}% –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ\n\n"
            
            f"üìÅ *–§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö:*\n"
        )
        
        data_files = [
            (STATE_FILE, "–°–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–ª–∏–∑–æ–≤"),
            (FILTERS_FILE, "–§–∏–ª—å—Ç—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"),
            (HISTORY_FILE, "–ò—Å—Ç–æ—Ä–∏—è —Ä–µ–ª–∏–∑–æ–≤"),
            (USERS_FILE, "–ë–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"),
            (STATISTICS_FILE, "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–æ—Ç–∞")
        ]
        
        for file_path, description in data_files:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                modified = datetime.fromtimestamp(os.path.getmtime(file_path))
                debug_info += f"‚úÖ {description}: {size:,} –±–∞–π—Ç ({modified.strftime('%d.%m %H:%M')})\n"
            else:
                debug_info += f"‚ùå {description}: —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç\n"
        
        debug_info += f"\nüîó *GitHub API:*\n"
        if GITHUB_TOKEN:
            debug_info += f"‚úÖ –¢–æ–∫–µ–Ω –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–¥–ª–∏–Ω–∞: {len(GITHUB_TOKEN)} —Å–∏–º–≤–æ–ª–æ–≤)\n"
        else:
            debug_info += f"‚ö†Ô∏è –¢–æ–∫–µ–Ω –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–≤–æ–∑–º–æ–∂–Ω—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)\n"
        
        debug_info += f"\n‚è∞ *–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫:*\n"
        try:
            from apscheduler.schedulers.asyncio import AsyncIOScheduler
            debug_info += f"‚úÖ –ú–æ–¥—É–ª—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –¥–æ—Å—Ç—É–ø–µ–Ω\n"
        except ImportError:
            debug_info += f"‚ùå –ú–æ–¥—É–ª—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\n"
        
        debug_info += f"\nüóÑÔ∏è *Supabase:*\n"
        try:
            from supabase_config import SupabaseManager
            supabase = SupabaseManager()
            debug_info += f"‚úÖ SupabaseManager –¥–æ—Å—Ç—É–ø–µ–Ω\n"
            if supabase.supabase_url:
                debug_info += f"‚Ä¢ URL: {supabase.supabase_url[:30]}...\n"
            if supabase.supabase_key:
                debug_info += f"‚Ä¢ –ö–ª—é—á: {supabase.supabase_key[:10]}...\n"
        except ImportError:
            debug_info += f"‚ùå –ú–æ–¥—É–ª—å Supabase –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\n"
        except Exception as e:
            debug_info += f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Supabase: {str(e)[:50]}...\n"
        
        debug_info += f"\nüîß *VPS –ø—Ä–æ—Ñ–∏–ª—å:* {VPS_PROFILE}\n"
        debug_info += f"‚öôÔ∏è *–ù–∞—Å—Ç—Ä–æ–π–∫–∏:*\n"
        debug_info += f"‚Ä¢ –ú–∞–∫—Å. –∑–∞–ø—Ä–æ—Å–æ–≤: {MAX_CONCURRENT_REQUESTS}\n"
        debug_info += f"‚Ä¢ –¢–∞–π–º–∞—É—Ç: {REQUEST_TIMEOUT}—Å\n"
        debug_info += f"‚Ä¢ –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞: {BATCH_SIZE}\n"
        debug_info += f"‚Ä¢ –ü–æ—Ä–æ–≥ –ø–∞–º—è—Ç–∏: {MEMORY_THRESHOLD_MB} –ú–ë"
        
        await message.answer(debug_info, parse_mode="Markdown")
        
    except ImportError:
        await message.answer(
            "‚ö†Ô∏è –ú–æ–¥—É–ª—å psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞.",
            parse_mode="Markdown"
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
        await message.answer(
            f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: `{str(e)}`",
            parse_mode="Markdown"
        )

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö –ù–ï–ò–ó–í–ï–°–¢–ù–´–• –ö–û–ú–ê–ù–î ---
async def unknown_command(message: Message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–∞–Ω–¥"""
    user_manager.add_user(message.from_user.id, message.from_user.username)
    
    command = message.text.split()[0] if message.text else "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞"
    logger.info(f"‚ùì –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {message.from_user.id} –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—É—é –∫–æ–º–∞–Ω–¥—É: {command}")
    
    await message.answer(
        f"‚ùì *–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞:* `{command}`\n\n"
        f"üìã –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–º–∞–Ω–¥.\n\n"
        f"üí° *–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:*\n"
        f"‚Ä¢ /start ‚Äî –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ\n"
        f"‚Ä¢ /filter ‚Äî –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã\n"
        f"‚Ä¢ /last ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–ª–∏–∑—ã\n"
        f"‚Ä¢ /help ‚Äî –ø–æ–ª–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞",
        parse_mode="Markdown"
    )

# --- –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ß–ò–ö–û–í ---
def register_handlers(dp: Dispatcher):
    """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤—Å–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ —Å–æ–±—ã—Ç–∏–π"""
    logger.info("üìù –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥...")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
    dp.message.register(start_command, CommandStart())
    dp.message.register(help_command, Command("help"))
    dp.message.register(donate_command, Command("donate"))
    
    # –ö–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    dp.message.register(filter_command, Command("filter"))
    dp.message.register(myfilters_command, Command("myfilters"))
    dp.message.register(clearfilters_command, Command("clearfilters"))
    
    # –ö–æ–º–∞–Ω–¥—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
    dp.message.register(last_command, Command("last"))
    
    # –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
    dp.message.register(stats_command, Command("stats"))
    dp.message.register(priority_command, Command("priority"))
    dp.message.register(sync_command, Command("sync"))
    dp.message.register(pstats_command, Command("pstats"))
    dp.message.register(checkall_command, Command("checkall"))
    dp.message.register(backup_command, Command("backup"))
    dp.message.register(debug_command, Command("debug"))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ callback-–∫–Ω–æ–ø–æ–∫
    dp.callback_query.register(cancel_filter_callback, F.data == "cancel_filter")
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤)
    dp.message.register(process_filter_text, F.text & ~F.command)
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–∞–Ω–¥ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–º)
    dp.message.register(unknown_command, F.text & F.text.startswith('/'))
    
    logger.info("‚úÖ –í—Å–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã")

# --- –§–£–ù–ö–¶–ò–Ø –û–ß–ò–°–¢–ö–ò –°–¢–ê–†–´–• –§–ê–ô–õ–û–í ---
async def cleanup_old_files():
    """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –ª–æ–≥–æ–≤ –∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
    logger.info("üßπ –ó–∞–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤...")
    
    try:
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ (—Å—Ç–∞—Ä—à–µ 14 –¥–Ω–µ–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞)
        log_dir = "logs"
        if os.path.exists(log_dir):
            cutoff_date = datetime.now() - timedelta(days=14)  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 30 –¥–æ 14
            
            for filename in os.listdir(log_dir):
                file_path = os.path.join(log_dir, filename)
                if os.path.isfile(file_path):
                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                    if file_time < cutoff_date:
                        os.remove(file_path)
                        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –ª–æ–≥: {filename}")
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π)
        if os.path.exists(BACKUP_DIR):
            cutoff_date = datetime.now() - timedelta(days=7)  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 14 –¥–æ 7
            
            for item in os.listdir(BACKUP_DIR):
                item_path = os.path.join(BACKUP_DIR, item)
                if os.path.isdir(item_path):
                    item_time = datetime.fromtimestamp(os.path.getmtime(item_path))
                    if item_time < cutoff_date:
                        shutil.rmtree(item_path)
                        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {item}")
        
        logger.info("‚úÖ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

# --- –§–£–ù–ö–¶–ò–Ø –ü–†–û–í–ï–†–ö–ò –ó–î–û–†–û–í–¨–Ø –ë–û–¢–ê ---
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–æ—Ç–∞ –∏ –µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    logger.info("üè• –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–æ—Ç–∞...")
    
    issues = []
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        required_files = [STATE_FILE, USERS_FILE]
        for file_path in required_files:
            if not os.path.exists(file_path):
                issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏
        if os.path.exists(HISTORY_FILE):
            size = os.path.getsize(HISTORY_FILE)
            if size > 25 * 1024 * 1024:  # –£–º–µ–Ω—å—à–µ–Ω–æ —Å 50 –¥–æ 25 –ú–ë
                issues.append(f"–§–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {size // 1024 // 1024} –ú–ë")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—à–∏–±–æ–∫
        error_rate = statistics_manager.stats.get('errors_count', 0)
        total_checks = statistics_manager.stats.get('total_checks', 1)
        if error_rate / max(total_checks, 1) > 0.15:  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 0.1 –¥–æ 0.15
            issues.append(f"–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –æ—à–∏–±–æ–∫: {error_rate}/{total_checks}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
        try:
            import psutil
            disk_usage = psutil.disk_usage('.')
            if disk_usage.percent > 95:  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 90 –¥–æ 95
                issues.append(f"–ú–∞–ª–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ: {disk_usage.percent}%")
        except ImportError:
            pass
        
        if issues:
            logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã: {'; '.join(issues)}")
        else:
            logger.info("‚úÖ –°–æ—Å—Ç–æ—è–Ω–∏–µ –±–æ—Ç–∞ –≤ –Ω–æ—Ä–º–µ")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")

# --- –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ---
async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è VPS"""
    print("=" * 50)
    print("üöÄ –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –ë–û–¢–ê –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê GITHUB –†–ï–õ–ò–ó–û–í")
    print("=" * 50)
    print(f"üîß VPS –ø—Ä–æ—Ñ–∏–ª—å: {VPS_PROFILE}")
    print(f"‚öôÔ∏è –ú–∞–∫—Å. –∑–∞–ø—Ä–æ—Å–æ–≤: {MAX_CONCURRENT_REQUESTS}")
    print(f"üì¶ –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞: {BATCH_SIZE}")
    print(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç: {REQUEST_TIMEOUT}—Å")
    print("=" * 50)

    if not BOT_TOKEN:
        logger.error("‚ùå BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
        print("–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ .env!")
        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –∏ –¥–æ–±–∞–≤—å—Ç–µ —Ç—É–¥–∞ BOT_TOKEN=–≤–∞—à_—Ç–æ–∫–µ–Ω")
        return

    if not ADMIN_ID:
        logger.error("‚ùå ADMIN_ID –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
        print("–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: ADMIN_ID –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

    logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞...")
    print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞...")

    bot = Bot(token=BOT_TOKEN)
    dp = Dispatcher()

    logger.info("üìù –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤...")
    print("üìù –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤...")
    register_handlers(dp)

    logger.info("‚è∞ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∑–∞–¥–∞—á...")
    print("‚è∞ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∑–∞–¥–∞—á...")
    
    scheduler = AsyncIOScheduler(timezone="UTC")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤ (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª)
    scheduler.add_job(
        check_repositories,
        'interval',
        minutes=MIN_CHECK_INTERVAL_MINUTES,
        kwargs={'bot': bot},
        id='repositories_check',
        max_instances=1,
        coalesce=True
    )

    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ (–∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤)
    scheduler.add_job(
        lambda: priority_manager.update_priorities(history_manager),
        'interval',
        hours=6,
        id='priority_update',
        max_instances=1
    )

    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ (–∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 03:00)
    scheduler.add_job(
        cleanup_old_files,
        'cron',
        hour=3,
        minute=0,
        id='cleanup_files',
        max_instances=1
    )

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –±–æ—Ç–∞ (–∫–∞–∂–¥—ã–µ 4 —á–∞—Å–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤)
    scheduler.add_job(
        health_check,
        'interval',
        hours=4,
        id='health_check',
        max_instances=1
    )

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–∫–∞–∂–¥—ã–π —á–∞—Å)
    scheduler.add_job(
        lambda: statistics_manager._save_stats(),
        'interval',
        hours=1,
        id='save_statistics',
        max_instances=1
    )

    logger.info("‚úÖ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
    print("‚úÖ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")

    scheduler.start()
    logger.info("‚è∞ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—É—â–µ–Ω")
    print("‚è∞ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—É—â–µ–Ω")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    logger.info("üóÑÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    print("üóÑÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    try:
        await priority_manager.initialize_priorities()
        logger.info("‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ –ë–î")
        print("‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ –ë–î")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤: {e}")
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤: {e}")

    print(f"\nüìä –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ë–û–¢–ê:")
    print(f"‚îú‚îÄ‚îÄ –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(REPOS)}")
    print(f"‚îú‚îÄ‚îÄ GitHub —Ç–æ–∫–µ–Ω: {'‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω' if GITHUB_TOKEN else '‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'}")
    print(f"‚îú‚îÄ‚îÄ –ö–∞–Ω–∞–ª –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: {'‚úÖ ' + CHANNEL_ID if CHANNEL_ID else '‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'}")
    print(f"‚îú‚îÄ‚îÄ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä: {'‚úÖ ID=' + str(ADMIN_ID) if ADMIN_ID else '‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'}")
    print(f"‚îú‚îÄ‚îÄ VPS –ø—Ä–æ—Ñ–∏–ª—å: {VPS_PROFILE}")
    print(f"‚îú‚îÄ‚îÄ –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {MIN_CHECK_INTERVAL_MINUTES}-{MAX_CHECK_INTERVAL_MINUTES} –º–∏–Ω")
    print(f"‚îî‚îÄ‚îÄ –•—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏: {HISTORY_DAYS} –¥–Ω–µ–π")

    logger.info("üéØ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")
    print("\nüéØ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤...")
    
    try:
        await check_all_repositories(bot)
        logger.info("‚úÖ –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        print("‚úÖ –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
        print("–ë–æ—Ç –±—É–¥–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–∞–±–æ—Ç—É, –Ω–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–º–∏")

    # –£–≤–µ–¥–æ–º–ª—è–µ–º –∞–¥–º–∏–Ω–∞ –æ –∑–∞–ø—É—Å–∫–µ
    if ADMIN_ID:
        try:
            startup_message = (
                f"üöÄ *–ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω!*\n\n"
                f"‚è∞ –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"üì¶ –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤: {len(REPOS)}\n"
                f"üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –±–∞–∑–µ: {user_manager.get_count()}\n"
                f"üîç –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏: {filter_manager.get_users_with_filters_count()}\n"
                f"üìà –†–µ–ª–∏–∑–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏: {history_manager.get_count()}\n\n"
                f"üîß *VPS –ø—Ä–æ—Ñ–∏–ª—å:* {VPS_PROFILE}\n"
                f"‚öôÔ∏è *–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:* –ú–∞–∫—Å. –∑–∞–ø—Ä–æ—Å–æ–≤ {MAX_CONCURRENT_REQUESTS}, "
                f"–ø–∞–∫–µ—Ç {BATCH_SIZE}, —Ç–∞–π–º–∞—É—Ç {REQUEST_TIMEOUT}—Å\n\n"
                f"–ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ! üéâ"
            )
            await bot.send_message(ADMIN_ID, startup_message, parse_mode="Markdown")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–ø—É—Å–∫–µ –∞–¥–º–∏–Ω—É: {e}")

    logger.info("üéâ –ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    print("\n" + "=" * 50)
    print("üéâ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ë–û–¢ –£–°–ü–ï–®–ù–û –ó–ê–ü–£–©–ï–ù –ò –ì–û–¢–û–í –ö –†–ê–ë–û–¢–ï!")
    print("=" * 50)
    print("üì± –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–æ—Ç–∞")
    print("üìã –õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫—É logs/")
    print("üíæ –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è –≤ –ø–∞–ø–∫—É backups/")
    print(f"üîß VPS –ø—Ä–æ—Ñ–∏–ª—å: {VPS_PROFILE}")
    print("=" * 50 + "\n")

    try:
        await dp.start_polling(bot, skip_updates=True)
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        print("\n‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–æ–ª–ª–∏–Ω–≥–∞: {e}")
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    finally:
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞...")
        print("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞...")
        
        try:
            scheduler.shutdown(wait=True)
            logger.info("‚è∞ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            print("‚è∞ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {e}")

        try:
            statistics_manager._save_stats()
            logger.info("üíæ –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            print("üíæ –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

        try:
            await bot.session.close()
            logger.info("üîå –°–µ—Å—Å–∏—è –±–æ—Ç–∞ –∑–∞–∫—Ä—ã—Ç–∞")
            print("üîå –°–µ—Å—Å–∏—è –±–æ—Ç–∞ –∑–∞–∫—Ä—ã—Ç–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è —Å–µ—Å—Å–∏–∏: {e}")

        if ADMIN_ID:
            try:
                shutdown_message = (
                    f"üõë *–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω*\n\n"
                    f"‚è∞ –í—Ä–µ–º—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                    f"üìä –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {statistics_manager.get_uptime()}\n"
                    f"üìà –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–æ–∫: {statistics_manager.stats['total_checks']}\n"
                    f"üîî –í—Å–µ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: {statistics_manager.stats['total_notifications_sent']}\n\n"
                    f"–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! üëã"
                )
                final_bot = Bot(token=BOT_TOKEN)
                await final_bot.send_message(ADMIN_ID, shutdown_message, parse_mode="Markdown")
                await final_bot.session.close()
            except:
                pass

        logger.info("‚úÖ –ë–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("‚úÖ –ë–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# --- –¢–û–ß–ö–ê –í–•–û–î–ê ---
if __name__ == "__main__":
    try:
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüëã –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {e}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        print(f"\nüí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        sys.exit(1)
